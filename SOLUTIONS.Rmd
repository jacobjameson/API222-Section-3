---
title: "Section 3 - More on Linear Regression: Exercises"
author: "Jacob Jameson"
output: pdf_document
---


As Professor Saghafian noted on Slide 14 of lecture 6, there are certain skills you are expected to have about inference in general, particularly when it comes to linear regression models. The goal of today's section is to practice (some of) these skills. The session involves executing coding exercises and answering conceptual questions along the way. We will work with the \textbf{\textit{Credit}} data set, which is a part of the \textbf{\textit{ISLR}} package. I will give you time to work on each subsection and then I will share my proposed code and answers to the questions. You are encouraged to work in pairs. 


```{r, include=FALSE}
# We need the ISLR library for the dataset
library(ISLR)

# We need this library to perfom KNN
library(FNN)

# Here, we also use the data.table package, 
# which is great for certain data cleaning/manipulation operations
# For more information, please check the documentation/vignette of the package
library(data.table)
```

Note that in some cases there are several ways to write the code to yield the same result. 

### 1 Exploratory data analysis

1. Load the Credit data set from ISLR package. Check the codebook to understand the
structure of the data set and the definition and unit of each variable.

```{r}
# Store the data in a clean object and cast the data into a "data.table" object
# As noted earlier this package simplifies some of the data cleaning...
credit_data  <- as.data.table(Credit) 
```

2. How many observations and variables does the data set include?

```{r}
dim(credit_data)
```

3. What are the categorical variables in the data set?

```{r}
str(credit_data)

# The categorical variables are: Gender, Student, Married, and Ethnicity.
```


4. Are they rows with missing values? If so, how many? Hint: checkout the `complete.cases` function.

```{r}
nrow(credit_data[!complete.cases(credit_data),])
```

5. Generate summary statistics of all the variables. What is the mean and standard deviation of income?

```{r}
summary(credit_data)
```

The mean income is: 

```{r}
round(mean(credit_data$Income, na.rm = TRUE), 2)
```

The standard deviation of income is:

```{r}
round(sd(credit_data$Income, na.rm = TRUE), 2)
```

6. Plot the relationship between balance (y-axis) and income (x-axis). What do you notice about the relationship?

```{r}
plot(x = credit_data$Income, y = credit_data$Balance,
     main = "Average credit card balance vs. Income",
     xlab = "Income",
     ylab = "Average credit card balance")

```



### 2 Inference

1. Regress balance (y-variable) on income (x-variable). Interpret the income coefficient.

```{r}
mod1 <- lm(Balance ~ Income, credit_data)
summary(mod1)

```



2. Now add gender as an explanatory variable.

```{r}

mod2 <- lm(Balance ~ Income + Gender, credit_data)
summary(mod2)


```


(a) Interpret all three coefficients (intercept, income coefficient, gender coefficient).



```{r}
# - The average balance for males is $233.77. 

# - The average balance for females is $24.31 higher than the average 
#   balance of males, when controlling for income. Note however, that this 
#   difference is not statistically significant. 

# - A $1,000 increase in income is associated with an average balance
#   increase of \$6.05. The coefficient is statistically significant.  

```



(b) Test the null hypothesis that there is no relationship between balance and gender (i.e. $\beta_{gender} = 0$). What do you conclude about the test?

```{r}
# - H0: the difference in balance between females and males 
#   (after controlling for income) is 0, that is $\beta_{gender} = 0$. 

# - Ha: the difference in balance between females and males
#   (after controlling for income) is different from 0, that is $\beta_{gender} \neq 0$.

# P-value suggests we cannot reject the NULL at any reasonable level of 
# significance (1\%, 5\%, 10\%)

```


(c) What is the confidence interval of the gender coefficient? Interpret this coefficient. Hint: checkout the \textit{confint} function.

```{r}

confint(mod2)


# We can be 95\% confident that the true difference in balance is between 
# females and males is between -55.99 and 104.61. Notice this interval 
# includes 0, which is consistent with our conclusion on the hypothesis test above. 
```


(d) Find and interpret the $R^2$ of this regression.


```{r}


# The $R^2$ is 0.2157. This means that income and gender together
# explain ~22\% of the variation in average card balance.
```


3. Now add an interaction term between income and gender to the regression in part 2.

(a) Interpret the coefficient on the interaction term.

```{r}

mod3 <- lm(Balance ~ Income*Gender, credit_data)
summary(mod3)

```


(b) What is $R^2$ and the adjusted $R^2$ of this regression. What do these two values tell you about the usefulness of the interaction term?


```{r}

# The $R^2$ is 0.2158 and the adjusted $R^2$ is 0.2098. In the model without the
# interaction term the $R^2$ was 0.2157, and the adjusted $R^2$ was 0.2117. 
# The $R^2$ has increased as expected given we have a added a term. 
# However, the adjusted adjusted $R^2$ has decreased suggesting the 
# interaction term does not add value 
# (when considering the complexity it adds to the model).
```

(c) Plot the residuals. What does the plot tell you about your model fit?

```{r}
plot(mod3$residuals)

# There's no discernible pattern in the residuals, the model fit appears reasonable.
```



4. Rerun the model in part 3 using the log-transformed version of the balance and income variables. Interpret the coefficient on the income term.

```{r}
mod4 <- lm(log(Balance + 0.0001) ~ log(Income)*Gender, credit_data)
summary(mod4)


# A 1\% increase in income is associated with 2.45\% decreases 
# average balance, when controlling for gender. 
```




#### 3 BONUS: Prediction

Now let's revisit prediction models using linear regression and KNN.

1. Prepare the input datasets

(a) Drop the ID column, the categorical columns, and any rows with missing values.

```{r}
# Remove rows with non-missing values
credit_data_complete <- credit_data[complete.cases(credit_data), ]

# Drop the district and municipality variables
credit_data_complete[, c("ID", "Gender", "Student", 
                         "Married", "Ethnicity") := NULL] # "data.table" syntax
```


(b) Randomly split the data into a training set (75% of the observations) and a test set (the remaining 25% of the observations).

```{r}
# Set a seed
set.seed(222)
# Extract the random test and training IDs
test_ids <- sample(seq(nrow(credit_data_complete)), 
                   round(0.25 * nrow(credit_data_complete)))

training_ids <- which(!(seq(nrow(credit_data_complete)) %in% test_ids))

# Now use the IDs to get the two sets
test_data <- credit_data_complete[test_ids,]
training_data <- credit_data_complete[training_ids,]
```

2. When you use your training data to build a linear model that regresses account balance on all other features available in the data (plus an intercept), what is your test Mean Squared Error?

```{r}

# The model
mod5 <- lm(Balance ~ ., training_data)

# Generate test predictions
predicted_bal <- predict(mod5, test_data[, -7])

## Let's see how well we did in terms of MSE
MSE_lm_bal <- mean((predicted_bal - test_data$Balance)^2)
print(MSE_lm_bal)

```

3. When you use your training data to build a KNN model that regresses account balance on all other features in the data, what is your test Mean Squared Error with $K = 1$?

```{r}
# Library for KNN regression
library(FNN)

# The model
knn_reg1 <- knn.reg(training_data[, -c(7)],
                    test_data[, -c(7)],
                    training_data$Balance,
                    k = 1)

# The MSE
mse_knn1 <- mean((knn_reg1$pred - test_data$Balance)^2)
print(mse_knn1)

```

4. In last Friday's review session, one of your classmates asked: "Instead of testing a few individual values of K, could we use a more systematic approach that computes the Mean Squared Error for many values of $K$ and then plot model performance as a function of $K$."

(a) In the first review session, we went through the basics of looping. Use a "for" loop to implement the approach your classmate suggested. Test $K$ values going from 1 to 100.

```{r}
# Define the range of K values to test
k_guesses <- 1:100

# Initialize a tracker for the MSE values for each K
mse_res <- NULL

# Now loop through all the values 
for(i in 1:length(k_guesses)){
  # For each value, run the model using the current K guess
  knn_reg <- knn.reg(training_data[, -c(7)],
                     test_data[, -c(7)],
                     training_data$Balance,
                     k = k_guesses[i]) # key line here
  
  # The MSE
  mse_knn <- mean((knn_reg$pred - test_data$Balance)^2)
  
  # Now update the tracker
  mse_res[i] <- mse_knn
}

# Now plot the results
plot(x = k_guesses, y = mse_res, main = "MSE vs. K", xlab = "K", ylab = "MSE")
```

(b) What can you conclude about the optimal $K$ value for this model.

```{r}
# Find the K that gives the minimum MSE
which.min(mse_res)

# It looks like $K = 8$ would give you the lowest MSE in this case. 
# Note: this result may be different from yours depending on how your sampling played out. 
```





